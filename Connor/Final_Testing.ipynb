{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣤⣤⡀⠀⠀⠀⠀⠀⠀\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⣿⣿⠟⠀⠀⠀⠀⠀⠀\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠻⣿⣷⣄⠀⠀⠀⠀⠀\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⣶⣿⡆⠀⠀⠉⠉⠀⠈⣶⡆⠀\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⢻⣷⠀\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⣿⡿⠟⠀⠀⠀⠀⠀⠀⠀⣸⣿⡄\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠙⣿⣷\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠛⠃⠀⠀⠀⠀⠀⠀⠀⠀⢰⣾⣿⠏\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣧⡔⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠟⠁⠀\n",
        "# ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⠇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
        "# Ah shit, here we go again.\n",
        "# < In case Google Drive neds to be mounted for data access >\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlEMn5XKVv3t",
        "outputId": "fb7a21b9-c21a-42da-8e9a-b72ca6ee517d"
      },
      "id": "xlEMn5XKVv3t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a95f6e9c",
      "metadata": {
        "id": "a95f6e9c",
        "outputId": "5428fd85-208c-497d-8c71-7b9f3715065d",
        "colab": {
          "referenced_widgets": [
            "5aae36667cfe40118876061de2e728ab",
            "f68cbd78049a4c36a6a788b083d502d5",
            "bd624921c74c4667b64bc36b41ab7e6c"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Valid(value=True, description='Success!')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aae36667cfe40118876061de2e728ab"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#   ,-.       _,---._ __  / \\\n",
        "#  /  )    .-'       `./ /   \\\n",
        "# (  (   ,'            `/    /|\n",
        "#  \\  `-\"             \\'\\   / |\n",
        "#   `.              ,  \\ \\ /  |\n",
        "#    /`.          ,'-`----Y   |\n",
        "#   (            ;        |   '\n",
        "#   |  ,-.    ,-'  Connor |  /\n",
        "#   |  | (   |   Contursi | /\n",
        "#   )  |  \\  `.___________|/\n",
        "#   `--'   `--'\n",
        "\n",
        "# Sets up widgets to use\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Lets you know if code was successful or not\n",
        "try:\n",
        "\n",
        "    import os\n",
        "    import shutil\n",
        "\n",
        "    import numpy as np\n",
        "    import imgaug as ia\n",
        "    import imgaug.augmenters as iaa\n",
        "\n",
        "    from tensorflow.keras import layers\n",
        "    from tensorflow import keras\n",
        "    import tensorflow as tf\n",
        "\n",
        "    from imgaug.augmentables.kps import KeypointsOnImage\n",
        "    from imgaug.augmentables.kps import Keypoint\n",
        "    import imgaug.augmenters as iaa\n",
        "\n",
        "    from PIL import Image\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from matplotlib import pyplot as plt\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import json\n",
        "    import os\n",
        "    import sys\n",
        "    import math\n",
        "    from skimage import io\n",
        "\n",
        "    import os\n",
        "    from PIL import Image\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from ast import literal_eval\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib.collections import LineCollection\n",
        "    import matplotlib.patches as patches\n",
        "    from tqdm.notebook import tnrange, tqdm\n",
        "\n",
        "    from distutils.dir_util import copy_tree\n",
        "\n",
        "    ia.seed(1)  # Seeds for testing repeatability\n",
        "\n",
        "    # Current main, working directory on desktop\n",
        "    # directory = \"C:/Users/indie/OneDrive/Desktop/CSC-495-Final-Project-main/\"\n",
        "    # os.chdir(directory)\n",
        "    \n",
        "    # Curren main, working directory on Google\n",
        "    directory = \"/content/drive/\" + \"MyDrive/\" # Google Drive\n",
        "    os.chdir(directory)\n",
        "    fold = False\n",
        "# ============================================================= #\n",
        "    success = widgets.Valid(value=True, description=\"Success!\",)\n",
        "    display(success)\n",
        "except Exception as e:\n",
        "    failure = widgets.Valid(value=False, description=\"Failure!\",)\n",
        "    display(failure)\n",
        "    print(e)\n",
        "# ============================================================= #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fcf510a",
      "metadata": {
        "id": "7fcf510a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7223cb67b8ad41a394fa1224c8ead3ab",
            "a22875f30d2c4b53a279f59e2d507a4d",
            "8c54aded01894d6c86ea6ea2e631c743"
          ]
        },
        "outputId": "7196d4ca-a159-4d3c-d572-1703e7f2c7f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Valid(value=True, description='Success!')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7223cb67b8ad41a394fa1224c8ead3ab"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "try:\n",
        "    # Pulls image keypoints and sets directories\n",
        "    # < For desktop >\n",
        "    # home_directory = directory # Source\n",
        "    # image_dir = \"images/\" # Source\n",
        "    # image_path = os.path.join(home_directory, image_dir)  # Source\n",
        "    # < For Google Colab >\n",
        "    home_directory = directory # Source\n",
        "    image_dir = \"Data/\" # Source\n",
        "    sorted_images = os.path.join(home_directory, \"TestTrainVal/\")\n",
        "    csv_dir = \"Set/\"\n",
        "    image_path = os.path.join(home_directory, image_dir)  # Source\n",
        "\n",
        "    # < NOT MOVING PICTURES TO SORT BEFOREHAND >\n",
        "\n",
        "    # Training and testing paths created\n",
        "    # < For desktop >\n",
        "    # train_dir = os.path.join(home_directory, \"train/\") # Destination\n",
        "    # test_dir = os.path.join(home_directory, \"test/\")# Destination\n",
        "    # val_dir = os.path.join(home_directory, \"val/\")# Destination\n",
        "    # < For Google Colab >\n",
        "    train_dir = os.path.join(sorted_images, \"train/\") # Destination\n",
        "    test_dir = os.path.join(sorted_images, \"test/\")# Destination\n",
        "    val_dir = os.path.join(sorted_images, \"val/\")# Destination\n",
        "\n",
        "    # < Will only run if it's first execution >\n",
        "    if not fold:\n",
        "\n",
        "      fold = True # Stops sorting from happening again\n",
        "\n",
        "      # ------------------------------------------------ #\n",
        "      # Removes paths if they already exist [just in case]\n",
        "      # This also deletes all the data in each path!\n",
        "      if os.path.exists(train_dir):\n",
        "          shutil.rmtree(train_dir)\n",
        "\n",
        "      if os.path.exists(test_dir):\n",
        "          shutil.rmtree(test_dir)\n",
        "\n",
        "      if os.path.exists(val_dir):\n",
        "          shutil.rmtree(val_dir)\n",
        "      # ------------------------------------------------ #\n",
        "      # Creates new directory paths to split data\n",
        "      if not os.path.exists(train_dir):\n",
        "          os.makedirs(train_dir)# Destination\n",
        "\n",
        "      if not os.path.exists(test_dir):\n",
        "          os.makedirs(test_dir)# Destination\n",
        "\n",
        "      if not os.path.exists(val_dir):\n",
        "          os.makedirs(val_dir)# Destination\n",
        "      # ------------------------------------------------ #\n",
        "      # Counts all the files in a given directory.\n",
        "      file_count = sum([len(files) for r, d, files in os.walk(image_path)])\n",
        "      pic_count = 0\n",
        "\n",
        "      # ================================================ #\n",
        "      # Splits image data up for processing\n",
        "      with tqdm(total=file_count) as pbar:\n",
        "          for subdir, dirs, files in os.walk(image_path):\n",
        "              for file in files:\n",
        "                  os.chdir(subdir)\n",
        "                  pic_count += 1  # Count of the pictures found\n",
        "                  dir_path = os.path.dirname(os.path.abspath(file))  # Current folder path\n",
        "\n",
        "                  image_loc = os.path.join(dir_path, file) # < Needed to sort images in Google Drive >\n",
        "\n",
        "                  # 10-10-80 Split by moving images to new folders\n",
        "                  if pic_count < int(file_count * 0.1):\n",
        "                      #copy_tree(dir_path, val_dir)  # 10% Validation\n",
        "                      # test = os.path.join(dir_path, val_dir)\n",
        "                      # print(test)\n",
        "                      shutil.copy(image_loc, val_dir) # < Needed to sort images in Google Drive >\n",
        "                  # ----------------- #\n",
        "                  elif int(file_count * 0.1) < pic_count < int(file_count * 0.2):\n",
        "                      # copy_tree(dir_path, test_dir)  # 10% Test\n",
        "                      # test = os.path.join(dir_path, test_dir)\n",
        "                      # print(test)\n",
        "                      shutil.copy(image_loc, test_dir) # < Needed to sort images in Google Drive >\n",
        "                  # ----------------- #\n",
        "                  else:\n",
        "                      # copy_tree(dir_path, train_dir)  # 80% Training\n",
        "                      # print(test)\n",
        "                      shutil.copy(image_loc, train_dir) # < Needed to sort images in Google Drive >\n",
        "                  pbar.update(1)\n",
        "      # ================================================ #\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================= #\n",
        "    success = widgets.Valid(value=True, description=\"Success!\",)\n",
        "    display(success)\n",
        "except Exception as e:\n",
        "    failure = widgets.Valid(value=False, description=\"Failure!\",)\n",
        "    display(failure)\n",
        "    print(e)\n",
        "# ============================================================= #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold = True"
      ],
      "metadata": {
        "id": "dkAsQ8wSj5f3"
      },
      "id": "dkAsQ8wSj5f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Importing &** **Processing**"
      ],
      "metadata": {
        "id": "m199hCJ2gNC7"
      },
      "id": "m199hCJ2gNC7"
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# data = pd.read_csv(os.path.join(directory, \"Set/mpii_dataset - update.csv\"))\n",
        "from os.path import dirname, join as pjoin\n",
        "import scipy.io as sio\n",
        "\n",
        "jsonfuck = os.path.join(directory, \"Set/test_fuck.json\")\n",
        "matfuck = os.path.join(directory, \"Set/mpii_human_pose_v1_u12_1.mat\")\n",
        "\n",
        "cunt = json.dumps(sio.loadmat(matfuck)[\"RELEASE\"].tolist())\n",
        "\n",
        "with open(jsonfuck, 'w') as jsonf:\n",
        "  jsonf.write(cunt)\n",
        "\n",
        "# # data = data.drop(data.columns[[0]], axis=1)\n",
        "# test = data.to_numpy()\n",
        "# # temp = []\n",
        "# columns_ = [\"image_name\", \"joint_pos\"]\n",
        "# frame = pd.DataFrame(columns = columns_)\n",
        "\n",
        "# # print(data.iloc[0:4, 0:5])\n",
        "# print(test)\n",
        "# joint_positions = []\n",
        "# image_names = []\n",
        "\n",
        "# for i in range(0, 2):\n",
        "#   for b in range(0, 5):\n",
        "#     temp = pd.DataFrame(data.iloc[b:, i:])\n",
        "#     print(temp)\n",
        "\n",
        "# print(frame)\n",
        "# temp[0][0] = \"image_name\"\n",
        "# for i in test.size:\n",
        "# print(temp)\n",
        "# print(test[1][0])# data.drop(data.index[5:], inplace=True)\n",
        "# print(data)"
      ],
      "metadata": {
        "id": "X0j96YVvikQB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "ab62397e-f36a-46bd-9eca-ecade0267745"
      },
      "id": "X0j96YVvikQB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-0a1a33f0f070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmatfuck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Set/mpii_human_pose_v1_u12_1.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcunt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatfuck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RELEASE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonfuck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "# test_csv = os.path.join(directory, \"Set/mpii_dataset - unmodified.csv\")\n",
        "# test_json = os.path.join(directory, \"Set/test_test.json\")\n",
        "# def make_json(test_csv, jsonFilePath):\n",
        "#     data = {}\n",
        "#     with open(test_csv, encoding='utf-8') as csvf:\n",
        "#       csvReader = csv.DictReader(csvf)\n",
        "#       for rows in csvReader:\n",
        "#           keys = rows['NAME']\n",
        "#           data[keys] = rows\n",
        "#     with open(test_json, 'w', orient=\"table\", encoding='utf-8') as jsonf:\n",
        "#         jsonf.write(json.dumps(data,indent=4))\n",
        "\n",
        "\n",
        "# make_json(test_csv, test_json)\n",
        "# testing = data.to_json(\"Set/test_test.json\", orient=\"table\")\n",
        "# parsed = json.loads(testing)\n",
        "# json.dumps(parsed, indent=4)  \n",
        "# outfile = os.path.join(directory, \"Set/test_test.json\")\n",
        "\n",
        "# with open(outfile, 'w', encoding='utf-8') as jsonf:\n",
        "#     jsonf.write(json.dumps(testing,indent=4))\n",
        "# cols = list(data.columns)\n",
        "# print(cols[0])\n",
        "# test = list(data)\n",
        "# print(type(data))\n",
        "# print(type(cols))\n",
        "# print(type(test))\n",
        "# print()\n",
        "# [j.pop(0) for j in test]\n",
        "# print()\n",
        "# for a in cols:\n",
        "#     del a[0]\n",
        "# test = cols.iloc[: , 1:]\n",
        "# test = np.array(cols.drop(\"Unnamed: 0\"))\n",
        "# # check if zero exist in string or integer\n",
        "# data.iloc[0, :] = data.replace(0, np.nan).bfill().iloc[0, :]\n",
        "# print(data)\n",
        "# df2= []\n",
        "# df = []\n",
        "# df2[cols] = df2[cols].replace({0:np.nan})\n",
        "\n",
        "# df[cols] = df[cols].bfill()"
      ],
      "metadata": {
        "id": "jXPdHGr8e6f8"
      },
      "id": "jXPdHGr8e6f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d1c9466",
      "metadata": {
        "id": "7d1c9466",
        "outputId": "e81a1832-2d48-495e-cce8-865682dc8bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
        "\n",
        "\n",
        "def get_img(name):\n",
        "    data = data_json[name]\n",
        "    img_data = plt.imread(train_dir)\n",
        "    return img_data\n",
        "\n",
        "# try:\n",
        "  # Grabs keypoints dataset\n",
        "json_data = os.path.join(directory, \"Set/mpii_dataset.json\")\n",
        "key_dir = os.path.join(\"Set/\", \"mpii_dataset - update.csv\")\n",
        "data = pd.read_csv(os.path.join(directory, key_dir))\n",
        "\n",
        "with open(json_data) as infile:\n",
        "  data_json = json.load(infile)\n",
        "\n",
        "samples = list(data_json.keys())\n",
        "num_samples = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "selected_samples = np.random.choice(samples, num_samples, replace=False)\n",
        "\n",
        "images, keypoints = [], []\n",
        "\n",
        "for sample in selected_samples:\n",
        "    data = get_img(sample)\n",
        "    image = data[\"NAME\"]\n",
        "\n",
        "# Shuffles data rows\n",
        "# samples = data.to_numpy() # Converts to numpy array\n",
        "# np.random.shuffle(samples)\n",
        "\n",
        "# Creates keys based on 10-10-80 split\n",
        "# train_keys, validation_keys = (\n",
        "#     samples[int(len(samples) * 0.1) :],\n",
        "#     samples[: int(len(samples) * 0.1)],\n",
        "# )\n",
        "\n",
        "print(data_json)\n",
        "# data_json = data_json.decode(\"utf-8\")\n",
        "\n",
        "# json_dict = {i[\"img_path\"]: i for i in data_json}\n",
        "\n",
        "# # ============================================================= #\n",
        "#     success = widgets.Valid(value=True, description=\"Success!\",)\n",
        "#     display(success)\n",
        "# except Exception as e:\n",
        "#     failure = widgets.Valid(value=False, description=\"Failure!\",)\n",
        "#     display(failure)\n",
        "#     print(e)\n",
        "# # ============================================================= #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels = data[\"image_name\"].values.tolist()"
      ],
      "metadata": {
        "id": "TnBH1TQtl-j3"
      },
      "id": "TnBH1TQtl-j3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5b417b",
      "metadata": {
        "id": "af5b417b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "157a49c1-4953-414d-8636-5148f68074e5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3429e05eb069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mNUM_KEYPOINTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mfile_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;31m# images = [os.path.join(root, filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m#           for root, dirs, files in os.walk(image_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3429e05eb069>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mNUM_KEYPOINTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mfile_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;31m# images = [os.path.join(root, filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m#           for root, dirs, files in os.walk(image_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;31m# above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# Recurse into sub-directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# Note that scandir is global in this module due\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# to earlier import-*.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mscandir_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0monerror\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from imgaug.augmentables.kps import KeypointsOnImage\n",
        "from imgaug.augmentables.kps import Keypoint\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "# def get_images(folder):\n",
        "  # img_data = plt.imread(train_dir)\n",
        "  # img_data = img_data.astype(np.uint8)\n",
        "  # img_data = Image.fromarray(img_data)\n",
        "  # img_data = np.array(img_data)\n",
        "\n",
        "# train_dir\n",
        "ext = (\".jpg\")\n",
        "\n",
        "IMG_SIZE = 320\n",
        "NUM_KEYPOINTS = 30\n",
        "\n",
        "file_count = sum([len(files) for r, d, files in os.walk(image_path)])\n",
        "  # images = [os.path.join(root, filename)\n",
        "  #           for root, dirs, files in os.walk(image_path)\n",
        "  #           for filename in files\n",
        "  #           if filename.lower().endswith('.jpg')]\n",
        "  #             pbar.update(1)\n",
        "\n",
        "images = []\n",
        "\n",
        "with tqdm(total=file_count) as pbar:\n",
        "  for root, dirs, files in os.walk(image_path):\n",
        "    for file in files:\n",
        "      if file.lower().endswith(ext):\n",
        "        images.append(file)\n",
        "        pbar.update(1)\n",
        "\n",
        "\n",
        "#Combines images into a list\n",
        "# ic = []\n",
        "# for img in images:\n",
        "#     ic.append(io.imread(img))\n",
        "\n",
        "# a, b, c = ic[0].shape\n",
        "\n",
        "# train_dataset = KeyPointsDataset(train_keys, train_aug)\n",
        "# validation_dataset = KeyPointsDataset(validation_keys, test_aug, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(ica, y, test_size = 0.2)\n",
        "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
        "train_dataset = KeyPointsDataset(train_keys, train_aug)"
      ],
      "metadata": {
        "id": "AfYlp4bBn9-H"
      },
      "id": "AfYlp4bBn9-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    # Load the pre-trained weights of MobileNetV2 and freeze the weights\n",
        "    backbone = keras.applications.MobileNetV2(\n",
        "        weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    )\n",
        "    backbone.trainable = False\n",
        "\n",
        "    inputs = layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
        "    x = backbone(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.SeparableConv2D(\n",
        "        NUM_KEYPOINTS, kernel_size=5, strides=1, activation=\"relu\"\n",
        "    )(x)\n",
        "    outputs = layers.SeparableConv2D(\n",
        "        NUM_KEYPOINTS, kernel_size=3, strides=1, activation=\"sigmoid\"\n",
        "    )(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs, name=\"keypoint_detector\")"
      ],
      "metadata": {
        "id": "jVjYkYFJl43p"
      },
      "id": "jVjYkYFJl43p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_model().summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTLizXF0nS3T",
        "outputId": "dc9e76cd-748a-409a-9bf0-f83a2d209939"
      },
      "id": "ZTLizXF0nS3T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"keypoint_detector\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 320, 320, 3)]     0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 320, 320, 3)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLambd  (None, 320, 320, 3)      0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 10, 10, 1280)     2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 10, 1280)      0         \n",
            "                                                                 \n",
            " separable_conv2d (Separable  (None, 6, 6, 30)         70430     \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " separable_conv2d_1 (Separab  (None, 4, 4, 30)         1200      \n",
            " leConv2D)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,329,614\n",
            "Trainable params: 71,630\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(1e-4))\n",
        "model.fit(train_dataset, validation_data=validation_dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "N81BlC--nvHZ"
      },
      "id": "N81BlC--nvHZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "# model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(units=4096,activation=\"relu\"))\n",
        "# model.add(Dense(units=4096,activation=\"relu\"))\n",
        "# model.add(Dense(units=2, activation=\"softmax\"))\n",
        "\n",
        "# from tensorflow.keras.optimizers import Adam \n",
        "# opt = Adam(lr=0.001)\n",
        "# model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqnGOqswiGHe",
        "outputId": "9af82622-a8cb-4ff9-e88e-3ba39e84ccd3"
      },
      "id": "JqnGOqswiGHe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 112, 112, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 56, 56, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 28, 28, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 14, 14, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 7, 7, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 134,268,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO3wwYdelrep",
        "outputId": "20b4e415-f8c3-4740-e571-a163e4a40dd2"
      },
      "id": "WO3wwYdelrep",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Final Testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5aae36667cfe40118876061de2e728ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ValidModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ValidModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ValidView",
            "description": "Success!",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f68cbd78049a4c36a6a788b083d502d5",
            "readout": "Invalid",
            "style": "IPY_MODEL_bd624921c74c4667b64bc36b41ab7e6c",
            "value": true
          }
        },
        "f68cbd78049a4c36a6a788b083d502d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd624921c74c4667b64bc36b41ab7e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7223cb67b8ad41a394fa1224c8ead3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ValidModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ValidModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ValidView",
            "description": "Success!",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a22875f30d2c4b53a279f59e2d507a4d",
            "readout": "Invalid",
            "style": "IPY_MODEL_8c54aded01894d6c86ea6ea2e631c743",
            "value": true
          }
        },
        "a22875f30d2c4b53a279f59e2d507a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c54aded01894d6c86ea6ea2e631c743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}